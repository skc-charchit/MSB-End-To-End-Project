{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Work Station\\mlproject\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#Import Libraries\n",
    "from joblib import Parallel, delayed\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, chi2\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score, roc_curve, auc, confusion_matrix,precision_recall_fscore_support\n",
    "import optuna\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import ttest_ind\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>FirstPaymentDate</th>\n",
       "      <th>FirstTimeHomebuyer</th>\n",
       "      <th>MaturityDate</th>\n",
       "      <th>MSA</th>\n",
       "      <th>MIP</th>\n",
       "      <th>Units</th>\n",
       "      <th>Occupancy</th>\n",
       "      <th>OCLTV</th>\n",
       "      <th>DTI</th>\n",
       "      <th>...</th>\n",
       "      <th>PostalCode</th>\n",
       "      <th>LoanSeqNum</th>\n",
       "      <th>LoanPurpose</th>\n",
       "      <th>OrigLoanTerm</th>\n",
       "      <th>NumBorrowers</th>\n",
       "      <th>SellerName</th>\n",
       "      <th>ServicerName</th>\n",
       "      <th>EverDelinquent</th>\n",
       "      <th>MonthsDelinquent</th>\n",
       "      <th>MonthsInRepayment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>199902</td>\n",
       "      <td>0</td>\n",
       "      <td>202901</td>\n",
       "      <td>357</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>27</td>\n",
       "      <td>...</td>\n",
       "      <td>470</td>\n",
       "      <td>86314</td>\n",
       "      <td>2</td>\n",
       "      <td>360</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>199902</td>\n",
       "      <td>0</td>\n",
       "      <td>202901</td>\n",
       "      <td>387</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>73</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>688</td>\n",
       "      <td>259731</td>\n",
       "      <td>1</td>\n",
       "      <td>360</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>199902</td>\n",
       "      <td>0</td>\n",
       "      <td>202901</td>\n",
       "      <td>110</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>75</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>531</td>\n",
       "      <td>85110</td>\n",
       "      <td>1</td>\n",
       "      <td>360</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>199902</td>\n",
       "      <td>0</td>\n",
       "      <td>202901</td>\n",
       "      <td>125</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>787</td>\n",
       "      <td>18846</td>\n",
       "      <td>1</td>\n",
       "      <td>360</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>199902</td>\n",
       "      <td>0</td>\n",
       "      <td>202901</td>\n",
       "      <td>169</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>78</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>637</td>\n",
       "      <td>19227</td>\n",
       "      <td>1</td>\n",
       "      <td>360</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore  FirstPaymentDate  FirstTimeHomebuyer  MaturityDate  MSA  MIP  \\\n",
       "0            0            199902                   0        202901  357   25   \n",
       "1            0            199902                   0        202901  387    0   \n",
       "2            0            199902                   0        202901  110    0   \n",
       "3            0            199902                   0        202901  125    0   \n",
       "4            0            199902                   0        202901  169    0   \n",
       "\n",
       "   Units  Occupancy  OCLTV  DTI  ...  PostalCode  LoanSeqNum  LoanPurpose  \\\n",
       "0      1          1     89   27  ...         470       86314            2   \n",
       "1      1          1     73   17  ...         688      259731            1   \n",
       "2      1          1     75   16  ...         531       85110            1   \n",
       "3      1          1     76   14  ...         787       18846            1   \n",
       "4      1          1     78   18  ...         637       19227            1   \n",
       "\n",
       "   OrigLoanTerm  NumBorrowers  SellerName  ServicerName  EverDelinquent  \\\n",
       "0           360             1          17             9               0   \n",
       "1           360             0          18            13               0   \n",
       "2           360             1          17             9               0   \n",
       "3           360             1           2             2               0   \n",
       "4           360             1           2             2               0   \n",
       "\n",
       "   MonthsDelinquent  MonthsInRepayment  \n",
       "0                 0                 52  \n",
       "1                 0                144  \n",
       "2                 0                 67  \n",
       "3                 0                 35  \n",
       "4                 0                 54  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r\"D:\\Work Station\\mlproject\\notebbok\\dataset\\Encoded_LoanExport.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Target and Feature Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define target and features\n",
    "target_column = 'MonthsInRepayment'\n",
    "X = df.drop(target_column, axis=1)\n",
    "y = df[target_column]\n",
    "\n",
    "# Fill missing values or drop missing values\n",
    "X.fillna(X.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Split into train, validation, and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(X, y, test_size=0.2, val_size=0.2):\n",
    "    X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=test_size, random_state=42, stratify=y)\n",
    "    val_proportion = val_size / (1 - test_size)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=val_proportion, random_state=42, stratify=y_train_val)\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = split_data(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Scaling using Standard Scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(solver='liblinear', random_state=42),\n",
    "    # \"Support Vector Machine (SVM)\": SVC(probability=True, random_state=42),\n",
    "    \"Gaussian Discriminant Analysis (GDA)\": QDA(),\n",
    "    \"Feed Forward Neural Network\": MLPClassifier(random_state=42)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate models and its classification report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating Models with time stamp and memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score, classification_report, confusion_matrix\n",
    "\n",
    "def evaluate_model(name, model, X_val_scaled, y_val):\n",
    "    # Fit the model\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Predict on validation set\n",
    "    y_val_pred = model.predict(X_val_scaled)\n",
    "    \n",
    "    # Calculate probabilities if the model supports it\n",
    "    y_val_proba = None\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_val_proba = model.predict_proba(X_val_scaled)\n",
    "    \n",
    "    # Classification report\n",
    "    report = classification_report(y_val, y_val_pred, output_dict=True)\n",
    "    \n",
    "    # Precision, Recall, F1-Score\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_val, y_val_pred, average='weighted')\n",
    "    \n",
    "    # AUC ROC Score\n",
    "    auc_roc = None\n",
    "    if y_val_proba is not None:\n",
    "        try:\n",
    "            auc_roc = roc_auc_score(y_val, y_val_proba, multi_class='ovr')\n",
    "        except ValueError:\n",
    "            auc_roc = None  # Handle models that don't support probability prediction\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    conf_matrix = confusion_matrix(y_val, y_val_pred)\n",
    "    \n",
    "    return {\n",
    "        'Model': name,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1,\n",
    "        'AUC ROC': auc_roc,\n",
    "        'Classification Report': report,\n",
    "        'Confusion Matrix': conf_matrix\n",
    "    }\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Logistic Regression...\n",
      "Results for Logistic Regression:\n",
      "Precision: 0.020055255969820936\n",
      "Recall: 0.04040144107050952\n",
      "F1 Score: 0.02039007979714241\n",
      "AUC ROC: 0.6771710891518091\n",
      "Confusion Matrix:\n",
      "[[  0   2   0 ...   0   1   4]\n",
      " [  1   1   2 ...   3   1   1]\n",
      " [  0   2   0 ...   6   2   1]\n",
      " ...\n",
      " [  2   0   1 ... 315  24   5]\n",
      " [  0   0   0 ... 137 111  18]\n",
      " [  0   0   0 ...  14  91  39]]\n",
      "Classification Report:\n",
      "{'1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 95.0}, '2': {'precision': 0.02631578947368421, 'recall': 0.005917159763313609, 'f1-score': 0.00966183574879227, 'support': 169.0}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 180.0}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 204.0}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 213.0}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 221.0}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 206.0}, '8': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 218.0}, '9': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 224.0}, '10': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 206.0}, '11': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 235.0}, '12': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 265.0}, '13': {'precision': 0.125, 'recall': 0.006535947712418301, 'f1-score': 0.012422360248447204, 'support': 306.0}, '14': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 323.0}, '15': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 354.0}, '16': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 400.0}, '17': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 369.0}, '18': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 345.0}, '19': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 386.0}, '20': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 361.0}, '21': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 337.0}, '22': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 355.0}, '23': {'precision': 0.08823529411764706, 'recall': 0.006802721088435374, 'f1-score': 0.01263157894736842, 'support': 441.0}, '24': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 508.0}, '25': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 618.0}, '26': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 705.0}, '27': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 716.0}, '28': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 712.0}, '29': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 707.0}, '30': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 700.0}, '31': {'precision': 0.0449438202247191, 'recall': 0.004987531172069825, 'f1-score': 0.008978675645342313, 'support': 802.0}, '32': {'precision': 0.04304635761589404, 'recall': 0.014207650273224045, 'f1-score': 0.021364009860312245, 'support': 915.0}, '33': {'precision': 0.034108527131782945, 'recall': 0.02286902286902287, 'f1-score': 0.027380211574362167, 'support': 962.0}, '34': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 850.0}, '35': {'precision': 0.03, 'recall': 0.05066344993968637, 'f1-score': 0.03768506056527591, 'support': 829.0}, '36': {'precision': 0.02434782608695652, 'recall': 0.0175, 'f1-score': 0.020363636363636365, 'support': 800.0}, '37': {'precision': 0.012987012987012988, 'recall': 0.0013351134846461949, 'f1-score': 0.002421307506053269, 'support': 749.0}, '38': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 653.0}, '39': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 680.0}, '40': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 790.0}, '41': {'precision': 0.024, 'recall': 0.0032822757111597373, 'f1-score': 0.005774783445620789, 'support': 914.0}, '42': {'precision': 0.031578947368421054, 'recall': 0.005434782608695652, 'f1-score': 0.00927357032457496, 'support': 1104.0}, '43': {'precision': 0.0395778364116095, 'recall': 0.09897360703812316, 'f1-score': 0.05654450261780105, 'support': 1364.0}, '44': {'precision': 0.034395848776871754, 'recall': 0.15591397849462366, 'f1-score': 0.05635855702660027, 'support': 1488.0}, '45': {'precision': 0.040021344717182494, 'recall': 0.1006036217303823, 'f1-score': 0.057262836419163965, 'support': 1491.0}, '46': {'precision': 0.029197080291970802, 'recall': 0.002828854314002829, 'f1-score': 0.0051579626047711154, 'support': 1414.0}, '47': {'precision': 0.03210771620921802, 'recall': 0.043878273177636234, 'f1-score': 0.03708133971291866, 'support': 1413.0}, '48': {'precision': 0.031275720164609055, 'recall': 0.025745257452574527, 'f1-score': 0.028242289111854328, 'support': 1476.0}, '49': {'precision': 0.03748296228986824, 'recall': 0.10344827586206896, 'f1-score': 0.05502751375687844, 'support': 1595.0}, '50': {'precision': 0.03091661223601132, 'recall': 0.0886945658963148, 'f1-score': 0.04585082337746206, 'support': 1601.0}, '51': {'precision': 0.03946146703806871, 'recall': 0.10967741935483871, 'f1-score': 0.05804028678729942, 'support': 1550.0}, '52': {'precision': 0.03808908973531311, 'recall': 0.18553459119496854, 'f1-score': 0.06320299946438136, 'support': 1590.0}, '53': {'precision': 0.03934324659231722, 'recall': 0.16699539776462854, 'f1-score': 0.06368308888053152, 'support': 1521.0}, '54': {'precision': 0.03608247422680412, 'recall': 0.022082018927444796, 'f1-score': 0.0273972602739726, 'support': 1268.0}, '55': {'precision': 0.012295081967213115, 'recall': 0.00340522133938706, 'f1-score': 0.005333333333333333, 'support': 881.0}, '56': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 646.0}, '57': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 508.0}, '58': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 431.0}, '59': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 430.0}, '60': {'precision': 0.03580562659846547, 'recall': 0.026217228464419477, 'f1-score': 0.03027027027027027, 'support': 534.0}, '61': {'precision': 0.046822742474916385, 'recall': 0.025089605734767026, 'f1-score': 0.03267211201866978, 'support': 558.0}, '62': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 545.0}, '63': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 448.0}, '64': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 352.0}, '65': {'precision': 0.07142857142857142, 'recall': 0.0031545741324921135, 'f1-score': 0.006042296072507553, 'support': 317.0}, '66': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 279.0}, '67': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 280.0}, '68': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 250.0}, '69': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 253.0}, '70': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 218.0}, '71': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 209.0}, '72': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 219.0}, '73': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 231.0}, '74': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 200.0}, '75': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 201.0}, '76': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 202.0}, '77': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 216.0}, '78': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 199.0}, '79': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 181.0}, '80': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 159.0}, '81': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 139.0}, '82': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 116.0}, '83': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 107.0}, '84': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 113.0}, '85': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 117.0}, '86': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 110.0}, '87': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 110.0}, '88': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 102.0}, '89': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 94.0}, '90': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 86.0}, '91': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 85.0}, '92': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 90.0}, '93': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 82.0}, '94': {'precision': 0.23684210526315788, 'recall': 0.09782608695652174, 'f1-score': 0.13846153846153847, 'support': 92.0}, '95': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 75.0}, '96': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 73.0}, '97': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 82.0}, '98': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 79.0}, '99': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 82.0}, '100': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 75.0}, '101': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 78.0}, '102': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 78.0}, '103': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 78.0}, '104': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 79.0}, '105': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 82.0}, '106': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 81.0}, '107': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 81.0}, '108': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 106.0}, '109': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 111.0}, '110': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 105.0}, '111': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 95.0}, '112': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 73.0}, '113': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 65.0}, '114': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 62.0}, '115': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 67.0}, '116': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 57.0}, '117': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 59.0}, '118': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 73.0}, '119': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 87.0}, '120': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 114.0}, '121': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 130.0}, '122': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 124.0}, '123': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 129.0}, '124': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 116.0}, '125': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 96.0}, '126': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 91.0}, '127': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 80.0}, '128': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 72.0}, '129': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 75.0}, '130': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 74.0}, '131': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 64.0}, '132': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 65.0}, '133': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 78.0}, '134': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 68.0}, '135': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 72.0}, '136': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 73.0}, '137': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 75.0}, '138': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 81.0}, '139': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 76.0}, '140': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 81.0}, '141': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 89.0}, '142': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 80.0}, '143': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 75.0}, '144': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 76.0}, '145': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 68.0}, '146': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 60.0}, '147': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 56.0}, '148': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 58.0}, '149': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 59.0}, '150': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 61.0}, '151': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 65.0}, '152': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 66.0}, '153': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 64.0}, '154': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 64.0}, '155': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 58.0}, '156': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 64.0}, '157': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 67.0}, '158': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 56.0}, '159': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 62.0}, '160': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 62.0}, '161': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 58.0}, '162': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 59.0}, '163': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 58.0}, '164': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 54.0}, '165': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 65.0}, '166': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 58.0}, '167': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 65.0}, '168': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 68.0}, '169': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 68.0}, '170': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 63.0}, '171': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 65.0}, '172': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 53.0}, '173': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 53.0}, '174': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 55.0}, '175': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 49.0}, '176': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 40.0}, '177': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 38.0}, '178': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 41.0}, '179': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 34.0}, '180': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 32.0}, '181': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 34.0}, '182': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 40.0}, '183': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 39.0}, '184': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 37.0}, '185': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 36.0}, '186': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 33.0}, '187': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 35.0}, '188': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 39.0}, '189': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 43.0}, '190': {'precision': 0.07142857142857142, 'recall': 0.017241379310344827, 'f1-score': 0.027777777777777776, 'support': 58.0}, '191': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 26.0}, '192': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 30.0}, '193': {'precision': 0.08957415565345081, 'recall': 0.5169491525423728, 'f1-score': 0.15269086357947434, 'support': 118.0}, '194': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 38.0}, '195': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 28.0}, '196': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 30.0}, '197': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 61.0}, '198': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 26.0}, '199': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 31.0}, '200': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 22.0}, '201': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 26.0}, '202': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 25.0}, '203': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 20.0}, '204': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 20.0}, '205': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 21.0}, '206': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 30.0}, '207': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 22.0}, '208': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 55.0}, '209': {'precision': 0.1, 'recall': 0.003952569169960474, 'f1-score': 0.0076045627376425855, 'support': 253.0}, '210': {'precision': 0.0677128116938951, 'recall': 0.43568464730290457, 'f1-score': 0.1172093023255814, 'support': 723.0}, '211': {'precision': 0.05724600309437854, 'recall': 0.20593692022263452, 'f1-score': 0.08958837772397095, 'support': 539.0}, '212': {'precision': 0.052489905787348586, 'recall': 0.14942528735632185, 'f1-score': 0.07768924302788845, 'support': 261.0}, 'accuracy': 0.04040144107050952, 'macro avg': {'precision': 0.008274342212669487, 'recall': 0.012871670699822667, 'f1-score': 0.00663748192260413, 'support': 58290.0}, 'weighted avg': {'precision': 0.020055255969820936, 'recall': 0.04040144107050952, 'f1-score': 0.02039007979714241, 'support': 58290.0}}\n",
      "\n",
      "Evaluating Gaussian Discriminant Analysis (GDA)...\n",
      "Results for Gaussian Discriminant Analysis (GDA):\n",
      "Precision: 0.0025509111734045823\n",
      "Recall: 0.0008406244638874593\n",
      "F1 Score: 0.00040997790182884306\n",
      "AUC ROC: 0.5291907011374211\n",
      "Confusion Matrix:\n",
      "[[ 6  0  0 ...  0  0  0]\n",
      " [13  0  0 ...  0  0  0]\n",
      " [ 5  0  0 ...  0  0  0]\n",
      " ...\n",
      " [ 8  0  0 ...  1  0  0]\n",
      " [ 3  0  0 ...  0  0  0]\n",
      " [ 3  0  0 ...  0  0  0]]\n",
      "Classification Report:\n",
      "{'1': {'precision': 0.006818181818181818, 'recall': 0.06315789473684211, 'f1-score': 0.012307692307692308, 'support': 95.0}, '2': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 169.0}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 180.0}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 204.0}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 213.0}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 221.0}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 206.0}, '8': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 218.0}, '9': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 224.0}, '10': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 206.0}, '11': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 235.0}, '12': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 265.0}, '13': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 306.0}, '14': {'precision': 0.012987012987012988, 'recall': 0.0030959752321981426, 'f1-score': 0.005, 'support': 323.0}, '15': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 354.0}, '16': {'precision': 0.041666666666666664, 'recall': 0.005, 'f1-score': 0.008928571428571428, 'support': 400.0}, '17': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 369.0}, '18': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 345.0}, '19': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 386.0}, '20': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 361.0}, '21': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 337.0}, '22': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 355.0}, '23': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 441.0}, '24': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 508.0}, '25': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 618.0}, '26': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 705.0}, '27': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 716.0}, '28': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 712.0}, '29': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 707.0}, '30': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 700.0}, '31': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 802.0}, '32': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 915.0}, '33': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 962.0}, '34': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 850.0}, '35': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 829.0}, '36': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 800.0}, '37': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 749.0}, '38': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 653.0}, '39': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 680.0}, '40': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 790.0}, '41': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 914.0}, '42': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1104.0}, '43': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1364.0}, '44': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1488.0}, '45': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1491.0}, '46': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1414.0}, '47': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1413.0}, '48': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1476.0}, '49': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1595.0}, '50': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1601.0}, '51': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1550.0}, '52': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1590.0}, '53': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1521.0}, '54': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1268.0}, '55': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 881.0}, '56': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 646.0}, '57': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 508.0}, '58': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 431.0}, '59': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 430.0}, '60': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 534.0}, '61': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 558.0}, '62': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 545.0}, '63': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 448.0}, '64': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 352.0}, '65': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 317.0}, '66': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 279.0}, '67': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 280.0}, '68': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 250.0}, '69': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 253.0}, '70': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 218.0}, '71': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 209.0}, '72': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 219.0}, '73': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 231.0}, '74': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 200.0}, '75': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 201.0}, '76': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 202.0}, '77': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 216.0}, '78': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 199.0}, '79': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 181.0}, '80': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 159.0}, '81': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 139.0}, '82': {'precision': 0.008, 'recall': 0.008620689655172414, 'f1-score': 0.008298755186721992, 'support': 116.0}, '83': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 107.0}, '84': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 113.0}, '85': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 117.0}, '86': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 110.0}, '87': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 110.0}, '88': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 102.0}, '89': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 94.0}, '90': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 86.0}, '91': {'precision': 0.03333333333333333, 'recall': 0.011764705882352941, 'f1-score': 0.017391304347826087, 'support': 85.0}, '92': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 90.0}, '93': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 82.0}, '94': {'precision': 0.21428571428571427, 'recall': 0.09782608695652174, 'f1-score': 0.13432835820895522, 'support': 92.0}, '95': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 75.0}, '96': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 73.0}, '97': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 82.0}, '98': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 79.0}, '99': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 82.0}, '100': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 75.0}, '101': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 78.0}, '102': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 78.0}, '103': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 78.0}, '104': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 79.0}, '105': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 82.0}, '106': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 81.0}, '107': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 81.0}, '108': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 106.0}, '109': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 111.0}, '110': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 105.0}, '111': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 95.0}, '112': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 73.0}, '113': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 65.0}, '114': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 62.0}, '115': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 67.0}, '116': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 57.0}, '117': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 59.0}, '118': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 73.0}, '119': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 87.0}, '120': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 114.0}, '121': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 130.0}, '122': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 124.0}, '123': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 129.0}, '124': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 116.0}, '125': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 96.0}, '126': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 91.0}, '127': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 80.0}, '128': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 72.0}, '129': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 75.0}, '130': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 74.0}, '131': {'precision': 0.0024813895781637717, 'recall': 0.015625, 'f1-score': 0.004282655246252677, 'support': 64.0}, '132': {'precision': 0.0017421602787456446, 'recall': 0.015384615384615385, 'f1-score': 0.003129890453834116, 'support': 65.0}, '133': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 78.0}, '134': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 68.0}, '135': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 72.0}, '136': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 73.0}, '137': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 75.0}, '138': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 81.0}, '139': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 76.0}, '140': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 81.0}, '141': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 89.0}, '142': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 80.0}, '143': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 75.0}, '144': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 76.0}, '145': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 68.0}, '146': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 60.0}, '147': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 56.0}, '148': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 58.0}, '149': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 59.0}, '150': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 61.0}, '151': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 65.0}, '152': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 66.0}, '153': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 64.0}, '154': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 64.0}, '155': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 58.0}, '156': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 64.0}, '157': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 67.0}, '158': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 56.0}, '159': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 62.0}, '160': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 62.0}, '161': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 58.0}, '162': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 59.0}, '163': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 58.0}, '164': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 54.0}, '165': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 65.0}, '166': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 58.0}, '167': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 65.0}, '168': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 68.0}, '169': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 68.0}, '170': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 63.0}, '171': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 65.0}, '172': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 53.0}, '173': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 53.0}, '174': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 55.0}, '175': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 49.0}, '176': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 40.0}, '177': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 38.0}, '178': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 41.0}, '179': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 34.0}, '180': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 32.0}, '181': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 34.0}, '182': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 40.0}, '183': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 39.0}, '184': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 37.0}, '185': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 36.0}, '186': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 33.0}, '187': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 35.0}, '188': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 39.0}, '189': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 43.0}, '190': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 58.0}, '191': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 26.0}, '192': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 30.0}, '193': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 118.0}, '194': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 38.0}, '195': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 28.0}, '196': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 30.0}, '197': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 61.0}, '198': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 26.0}, '199': {'precision': 0.004149377593360996, 'recall': 0.06451612903225806, 'f1-score': 0.007797270955165692, 'support': 31.0}, '200': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 22.0}, '201': {'precision': 0.0005170144764053393, 'recall': 0.4230769230769231, 'f1-score': 0.0010327668763496385, 'support': 26.0}, '202': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 25.0}, '203': {'precision': 0.00039786986594846053, 'recall': 0.65, 'f1-score': 0.0007952529516119165, 'support': 20.0}, '204': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 20.0}, '205': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 21.0}, '206': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 30.0}, '207': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 22.0}, '208': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 55.0}, '209': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 253.0}, '210': {'precision': 0.14285714285714285, 'recall': 0.0013831258644536654, 'f1-score': 0.0027397260273972603, 'support': 723.0}, '211': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 539.0}, '212': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 261.0}, 'accuracy': 0.0008406244638874593, 'macro avg': {'precision': 0.0022133767157579065, 'recall': 0.006412505404817631, 'f1-score': 0.0009718502075017846, 'support': 58290.0}, 'weighted avg': {'precision': 0.0025509111734045823, 'recall': 0.0008406244638874593, 'f1-score': 0.00040997790182884306, 'support': 58290.0}}\n",
      "\n",
      "Evaluating Feed Forward Neural Network...\n",
      "Results for Feed Forward Neural Network:\n",
      "Precision: 0.03380087716785255\n",
      "Recall: 0.050128667009778693\n",
      "F1 Score: 0.030995650531331548\n",
      "AUC ROC: 0.7692393327454852\n",
      "Confusion Matrix:\n",
      "[[  5   4   5 ...   4   3   3]\n",
      " [  5  11  11 ...   2   2   1]\n",
      " [  5  13  15 ...   3   5   1]\n",
      " ...\n",
      " [  2   0   0 ... 405  59   9]\n",
      " [  1   0   2 ... 126 215  45]\n",
      " [  1   0   0 ...   3 121  87]]\n",
      "Classification Report:\n",
      "{'1': {'precision': 0.0641025641025641, 'recall': 0.05263157894736842, 'f1-score': 0.057803468208092484, 'support': 95.0}, '2': {'precision': 0.08029197080291971, 'recall': 0.0650887573964497, 'f1-score': 0.0718954248366013, 'support': 169.0}, '3': {'precision': 0.075, 'recall': 0.08333333333333333, 'f1-score': 0.07894736842105263, 'support': 180.0}, '4': {'precision': 0.043010752688172046, 'recall': 0.13725490196078433, 'f1-score': 0.06549707602339182, 'support': 204.0}, '5': {'precision': 0.037142857142857144, 'recall': 0.18309859154929578, 'f1-score': 0.06175771971496437, 'support': 213.0}, '6': {'precision': 0.07207207207207207, 'recall': 0.03619909502262444, 'f1-score': 0.04819277108433735, 'support': 221.0}, '7': {'precision': 0.017857142857142856, 'recall': 0.009708737864077669, 'f1-score': 0.012578616352201259, 'support': 206.0}, '8': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 218.0}, '9': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 224.0}, '10': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 206.0}, '11': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 235.0}, '12': {'precision': 0.05555555555555555, 'recall': 0.007547169811320755, 'f1-score': 0.013289036544850499, 'support': 265.0}, '13': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 306.0}, '14': {'precision': 0.06896551724137931, 'recall': 0.01238390092879257, 'f1-score': 0.02099737532808399, 'support': 323.0}, '15': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 354.0}, '16': {'precision': 0.045454545454545456, 'recall': 0.0025, 'f1-score': 0.004739336492890996, 'support': 400.0}, '17': {'precision': 0.04285714285714286, 'recall': 0.008130081300813009, 'f1-score': 0.01366742596810934, 'support': 369.0}, '18': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 345.0}, '19': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 386.0}, '20': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 361.0}, '21': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 337.0}, '22': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 355.0}, '23': {'precision': 0.03125, 'recall': 0.0045351473922902496, 'f1-score': 0.007920792079207921, 'support': 441.0}, '24': {'precision': 0.008695652173913044, 'recall': 0.001968503937007874, 'f1-score': 0.0032102728731942215, 'support': 508.0}, '25': {'precision': 0.04, 'recall': 0.003236245954692557, 'f1-score': 0.005988023952095809, 'support': 618.0}, '26': {'precision': 0.04067796610169491, 'recall': 0.03404255319148936, 'f1-score': 0.037065637065637064, 'support': 705.0}, '27': {'precision': 0.031914893617021274, 'recall': 0.008379888268156424, 'f1-score': 0.01327433628318584, 'support': 716.0}, '28': {'precision': 0.031007751937984496, 'recall': 0.0056179775280898875, 'f1-score': 0.009512485136741973, 'support': 712.0}, '29': {'precision': 0.025157232704402517, 'recall': 0.028288543140028287, 'f1-score': 0.02663115845539281, 'support': 707.0}, '30': {'precision': 0.02748091603053435, 'recall': 0.025714285714285714, 'f1-score': 0.026568265682656828, 'support': 700.0}, '31': {'precision': 0.07017543859649122, 'recall': 0.004987531172069825, 'f1-score': 0.009313154831199068, 'support': 802.0}, '32': {'precision': 0.03778605641298563, 'recall': 0.07759562841530054, 'f1-score': 0.05082319255547602, 'support': 915.0}, '33': {'precision': 0.027450980392156862, 'recall': 0.007276507276507277, 'f1-score': 0.011503697617091208, 'support': 962.0}, '34': {'precision': 0.03515625, 'recall': 0.021176470588235293, 'f1-score': 0.02643171806167401, 'support': 850.0}, '35': {'precision': 0.05546492659053834, 'recall': 0.08202653799758745, 'f1-score': 0.06618004866180048, 'support': 829.0}, '36': {'precision': 0.031496062992125984, 'recall': 0.005, 'f1-score': 0.008629989212513484, 'support': 800.0}, '37': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 749.0}, '38': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 653.0}, '39': {'precision': 0.019230769230769232, 'recall': 0.0029411764705882353, 'f1-score': 0.00510204081632653, 'support': 680.0}, '40': {'precision': 0.058823529411764705, 'recall': 0.002531645569620253, 'f1-score': 0.0048543689320388345, 'support': 790.0}, '41': {'precision': 0.028925619834710745, 'recall': 0.007658643326039387, 'f1-score': 0.012110726643598616, 'support': 914.0}, '42': {'precision': 0.04658197217180883, 'recall': 0.13949275362318841, 'f1-score': 0.06984126984126984, 'support': 1104.0}, '43': {'precision': 0.04383886255924171, 'recall': 0.027126099706744868, 'f1-score': 0.03351449275362319, 'support': 1364.0}, '44': {'precision': 0.04340677408747123, 'recall': 0.08870967741935484, 'f1-score': 0.0582910134687569, 'support': 1488.0}, '45': {'precision': 0.04353867531264474, 'recall': 0.06304493628437291, 'f1-score': 0.05150684931506849, 'support': 1491.0}, '46': {'precision': 0.032498902064119456, 'recall': 0.05233380480905234, 'f1-score': 0.04009753454348415, 'support': 1414.0}, '47': {'precision': 0.04759206798866856, 'recall': 0.059447983014861996, 'f1-score': 0.05286343612334802, 'support': 1413.0}, '48': {'precision': 0.04271844660194175, 'recall': 0.02981029810298103, 'f1-score': 0.035115722266560255, 'support': 1476.0}, '49': {'precision': 0.03950617283950617, 'recall': 0.08025078369905957, 'f1-score': 0.05294725956566701, 'support': 1595.0}, '50': {'precision': 0.040131940626717974, 'recall': 0.136789506558401, 'f1-score': 0.062057240011334655, 'support': 1601.0}, '51': {'precision': 0.04099935938500961, 'recall': 0.08258064516129032, 'f1-score': 0.0547945205479452, 'support': 1550.0}, '52': {'precision': 0.04665379665379665, 'recall': 0.09119496855345911, 'f1-score': 0.06172839506172839, 'support': 1590.0}, '53': {'precision': 0.045871559633027525, 'recall': 0.22682445759368836, 'f1-score': 0.07631055076310551, 'support': 1521.0}, '54': {'precision': 0.040740740740740744, 'recall': 0.03470031545741325, 'f1-score': 0.03747870528109029, 'support': 1268.0}, '55': {'precision': 0.03361344537815126, 'recall': 0.009080590238365494, 'f1-score': 0.014298480786416443, 'support': 881.0}, '56': {'precision': 0.02, 'recall': 0.0015479876160990713, 'f1-score': 0.0028735632183908046, 'support': 646.0}, '57': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 508.0}, '58': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 431.0}, '59': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 430.0}, '60': {'precision': 0.0622568093385214, 'recall': 0.0299625468164794, 'f1-score': 0.040455120101137804, 'support': 534.0}, '61': {'precision': 0.0743801652892562, 'recall': 0.016129032258064516, 'f1-score': 0.026509572901325478, 'support': 558.0}, '62': {'precision': 0.04580152671755725, 'recall': 0.011009174311926606, 'f1-score': 0.01775147928994083, 'support': 545.0}, '63': {'precision': 0.02127659574468085, 'recall': 0.002232142857142857, 'f1-score': 0.00404040404040404, 'support': 448.0}, '64': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 352.0}, '65': {'precision': 0.012048192771084338, 'recall': 0.0031545741324921135, 'f1-score': 0.005, 'support': 317.0}, '66': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 279.0}, '67': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 280.0}, '68': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 250.0}, '69': {'precision': 0.0625, 'recall': 0.003952569169960474, 'f1-score': 0.007434944237918215, 'support': 253.0}, '70': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 218.0}, '71': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 209.0}, '72': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 219.0}, '73': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 231.0}, '74': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 200.0}, '75': {'precision': 0.038461538461538464, 'recall': 0.004975124378109453, 'f1-score': 0.00881057268722467, 'support': 201.0}, '76': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 202.0}, '77': {'precision': 0.012658227848101266, 'recall': 0.004629629629629629, 'f1-score': 0.006779661016949152, 'support': 216.0}, '78': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 199.0}, '79': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 181.0}, '80': {'precision': 0.05555555555555555, 'recall': 0.006289308176100629, 'f1-score': 0.011299435028248588, 'support': 159.0}, '81': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 139.0}, '82': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 116.0}, '83': {'precision': 0.14285714285714285, 'recall': 0.009345794392523364, 'f1-score': 0.017543859649122806, 'support': 107.0}, '84': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 113.0}, '85': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 117.0}, '86': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 110.0}, '87': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 110.0}, '88': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 102.0}, '89': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 94.0}, '90': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 86.0}, '91': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 85.0}, '92': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 90.0}, '93': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 82.0}, '94': {'precision': 0.39285714285714285, 'recall': 0.2391304347826087, 'f1-score': 0.2972972972972973, 'support': 92.0}, '95': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 75.0}, '96': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 73.0}, '97': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 82.0}, '98': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 79.0}, '99': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 82.0}, '100': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 75.0}, '101': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 78.0}, '102': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 78.0}, '103': {'precision': 0.2, 'recall': 0.01282051282051282, 'f1-score': 0.024096385542168676, 'support': 78.0}, '104': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 79.0}, '105': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 82.0}, '106': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 81.0}, '107': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 81.0}, '108': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 106.0}, '109': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 111.0}, '110': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 105.0}, '111': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 95.0}, '112': {'precision': 0.4, 'recall': 0.0273972602739726, 'f1-score': 0.05128205128205128, 'support': 73.0}, '113': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 65.0}, '114': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 62.0}, '115': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 67.0}, '116': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 57.0}, '117': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 59.0}, '118': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 73.0}, '119': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 87.0}, '120': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 114.0}, '121': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 130.0}, '122': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 124.0}, '123': {'precision': 0.05555555555555555, 'recall': 0.015503875968992248, 'f1-score': 0.024242424242424242, 'support': 129.0}, '124': {'precision': 0.045454545454545456, 'recall': 0.008620689655172414, 'f1-score': 0.014492753623188406, 'support': 116.0}, '125': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 96.0}, '126': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 91.0}, '127': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 80.0}, '128': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 72.0}, '129': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 75.0}, '130': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 74.0}, '131': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 64.0}, '132': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 65.0}, '133': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 78.0}, '134': {'precision': 0.2, 'recall': 0.014705882352941176, 'f1-score': 0.0273972602739726, 'support': 68.0}, '135': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 72.0}, '136': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 73.0}, '137': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 75.0}, '138': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 81.0}, '139': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 76.0}, '140': {'precision': 0.058823529411764705, 'recall': 0.012345679012345678, 'f1-score': 0.02040816326530612, 'support': 81.0}, '141': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 89.0}, '142': {'precision': 0.09375, 'recall': 0.0375, 'f1-score': 0.05357142857142857, 'support': 80.0}, '143': {'precision': 0.1, 'recall': 0.013333333333333334, 'f1-score': 0.023529411764705882, 'support': 75.0}, '144': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 76.0}, '145': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 68.0}, '146': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 60.0}, '147': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 56.0}, '148': {'precision': 0.1111111111111111, 'recall': 0.034482758620689655, 'f1-score': 0.05263157894736842, 'support': 58.0}, '149': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 59.0}, '150': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 61.0}, '151': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 65.0}, '152': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 66.0}, '153': {'precision': 0.03125, 'recall': 0.015625, 'f1-score': 0.020833333333333332, 'support': 64.0}, '154': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 64.0}, '155': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 58.0}, '156': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 64.0}, '157': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 67.0}, '158': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 56.0}, '159': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 62.0}, '160': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 62.0}, '161': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 58.0}, '162': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 59.0}, '163': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 58.0}, '164': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 54.0}, '165': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 65.0}, '166': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 58.0}, '167': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 65.0}, '168': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 68.0}, '169': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 68.0}, '170': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 63.0}, '171': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 65.0}, '172': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 53.0}, '173': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 53.0}, '174': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 55.0}, '175': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 49.0}, '176': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 40.0}, '177': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 38.0}, '178': {'precision': 0.25, 'recall': 0.07317073170731707, 'f1-score': 0.11320754716981132, 'support': 41.0}, '179': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 34.0}, '180': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 32.0}, '181': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 34.0}, '182': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 40.0}, '183': {'precision': 0.13333333333333333, 'recall': 0.05128205128205128, 'f1-score': 0.07407407407407407, 'support': 39.0}, '184': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 37.0}, '185': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 36.0}, '186': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 33.0}, '187': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 35.0}, '188': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 39.0}, '189': {'precision': 0.08108108108108109, 'recall': 0.06976744186046512, 'f1-score': 0.075, 'support': 43.0}, '190': {'precision': 0.07804878048780488, 'recall': 0.27586206896551724, 'f1-score': 0.12167300380228137, 'support': 58.0}, '191': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 26.0}, '192': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 30.0}, '193': {'precision': 0.12224938875305623, 'recall': 0.423728813559322, 'f1-score': 0.18975332068311196, 'support': 118.0}, '194': {'precision': 0.030303030303030304, 'recall': 0.02631578947368421, 'f1-score': 0.028169014084507043, 'support': 38.0}, '195': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 28.0}, '196': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 30.0}, '197': {'precision': 0.07692307692307693, 'recall': 0.16393442622950818, 'f1-score': 0.10471204188481675, 'support': 61.0}, '198': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 26.0}, '199': {'precision': 0.125, 'recall': 0.03225806451612903, 'f1-score': 0.05128205128205128, 'support': 31.0}, '200': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 22.0}, '201': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 26.0}, '202': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 25.0}, '203': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 20.0}, '204': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 20.0}, '205': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 21.0}, '206': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 30.0}, '207': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 22.0}, '208': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 55.0}, '209': {'precision': 0.06598984771573604, 'recall': 0.1541501976284585, 'f1-score': 0.0924170616113744, 'support': 253.0}, '210': {'precision': 0.12046400951814396, 'recall': 0.5601659751037344, 'f1-score': 0.19828641370869032, 'support': 723.0}, '211': {'precision': 0.09223509223509224, 'recall': 0.39888682745825604, 'f1-score': 0.14982578397212543, 'support': 539.0}, '212': {'precision': 0.10057803468208093, 'recall': 0.3333333333333333, 'f1-score': 0.15452930728241562, 'support': 261.0}, 'accuracy': 0.050128667009778693, 'macro avg': {'precision': 0.025016510362501344, 'recall': 0.024197119273377154, 'f1-score': 0.016917647726570624, 'support': 58290.0}, 'weighted avg': {'precision': 0.03380087716785255, 'recall': 0.050128667009778693, 'f1-score': 0.030995650531331548, 'support': 58290.0}}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for name, model in models.items():\n",
    "    print(f\"Evaluating {name}...\")\n",
    "    result = evaluate_model(name, model, X_val_scaled, y_val)\n",
    "    results.append(result)\n",
    "    print(f\"Results for {name}:\")\n",
    "    print(f\"Precision: {result['Precision']}\")\n",
    "    print(f\"Recall: {result['Recall']}\")\n",
    "    print(f\"F1 Score: {result['F1 Score']}\")\n",
    "    print(f\"AUC ROC: {result['AUC ROC']}\")\n",
    "    print(f\"Confusion Matrix:\\n{result['Confusion Matrix']}\")\n",
    "    print(f\"Classification Report:\\n{result['Classification Report']}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             Model Name   AUC ROC\n",
      "2           Feed Forward Neural Network  0.769239\n",
      "0                   Logistic Regression  0.677171\n",
      "1  Gaussian Discriminant Analysis (GDA)  0.529191\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have lists of model names and their corresponding AUC ROC scores\n",
    "model_names = [result['Model'] for result in results]\n",
    "auc_roc_scores = [result['AUC ROC'] for result in results]\n",
    "\n",
    "# Create a DataFrame and sort it by AUC ROC score in descending order\n",
    "results_df = pd.DataFrame(list(zip(model_names, auc_roc_scores)), columns=['Model Name', 'AUC ROC']).sort_values(by=[\"AUC ROC\"], ascending=False)\n",
    "\n",
    "# Print the sorted DataFrame\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Test Set:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.10      0.07      0.08        95\n",
      "           2       0.07      0.06      0.06       170\n",
      "           3       0.05      0.06      0.05       180\n",
      "           4       0.05      0.17      0.08       204\n",
      "           5       0.04      0.19      0.06       213\n",
      "           6       0.04      0.02      0.03       220\n",
      "           7       0.02      0.01      0.01       206\n",
      "           8       0.00      0.00      0.00       217\n",
      "           9       0.07      0.00      0.01       224\n",
      "          10       0.00      0.00      0.00       205\n",
      "          11       0.00      0.00      0.00       235\n",
      "          12       0.03      0.00      0.01       265\n",
      "          13       0.03      0.00      0.01       306\n",
      "          14       0.03      0.00      0.01       323\n",
      "          15       0.00      0.00      0.00       354\n",
      "          16       0.08      0.01      0.01       400\n",
      "          17       0.07      0.01      0.02       369\n",
      "          18       0.00      0.00      0.00       345\n",
      "          19       0.25      0.00      0.01       386\n",
      "          20       0.03      0.00      0.01       361\n",
      "          21       0.00      0.00      0.00       337\n",
      "          22       0.04      0.01      0.01       355\n",
      "          23       0.08      0.01      0.02       441\n",
      "          24       0.02      0.00      0.01       508\n",
      "          25       0.02      0.00      0.00       618\n",
      "          26       0.02      0.02      0.02       705\n",
      "          27       0.03      0.01      0.01       716\n",
      "          28       0.02      0.00      0.00       713\n",
      "          29       0.03      0.04      0.04       707\n",
      "          30       0.03      0.03      0.03       700\n",
      "          31       0.01      0.00      0.00       802\n",
      "          32       0.04      0.08      0.05       915\n",
      "          33       0.02      0.01      0.01       962\n",
      "          34       0.04      0.02      0.03       850\n",
      "          35       0.05      0.07      0.06       829\n",
      "          36       0.05      0.01      0.01       800\n",
      "          37       0.01      0.00      0.00       749\n",
      "          38       0.03      0.00      0.01       653\n",
      "          39       0.05      0.01      0.01       680\n",
      "          40       0.05      0.00      0.00       791\n",
      "          41       0.03      0.01      0.01       914\n",
      "          42       0.04      0.13      0.07      1104\n",
      "          43       0.04      0.02      0.03      1364\n",
      "          44       0.05      0.09      0.06      1488\n",
      "          45       0.04      0.06      0.05      1491\n",
      "          46       0.04      0.07      0.05      1414\n",
      "          47       0.06      0.07      0.06      1413\n",
      "          48       0.04      0.03      0.04      1476\n",
      "          49       0.05      0.09      0.06      1595\n",
      "          50       0.05      0.15      0.07      1600\n",
      "          51       0.04      0.08      0.05      1551\n",
      "          52       0.04      0.08      0.05      1589\n",
      "          53       0.05      0.24      0.08      1521\n",
      "          54       0.04      0.04      0.04      1268\n",
      "          55       0.01      0.00      0.01       881\n",
      "          56       0.00      0.00      0.00       646\n",
      "          57       0.02      0.00      0.00       508\n",
      "          58       0.03      0.00      0.00       431\n",
      "          59       0.07      0.00      0.00       430\n",
      "          60       0.07      0.04      0.05       535\n",
      "          61       0.05      0.01      0.02       558\n",
      "          62       0.05      0.01      0.02       545\n",
      "          63       0.00      0.00      0.00       448\n",
      "          64       0.03      0.01      0.01       351\n",
      "          65       0.03      0.01      0.01       317\n",
      "          66       0.00      0.00      0.00       279\n",
      "          67       0.00      0.00      0.00       280\n",
      "          68       0.00      0.00      0.00       250\n",
      "          69       0.00      0.00      0.00       253\n",
      "          70       0.00      0.00      0.00       218\n",
      "          71       0.00      0.00      0.00       209\n",
      "          72       0.00      0.00      0.00       219\n",
      "          73       0.06      0.00      0.01       231\n",
      "          74       0.00      0.00      0.00       201\n",
      "          75       0.00      0.00      0.00       202\n",
      "          76       0.00      0.00      0.00       202\n",
      "          77       0.01      0.00      0.01       216\n",
      "          78       0.00      0.00      0.00       199\n",
      "          79       0.00      0.00      0.00       181\n",
      "          80       0.00      0.00      0.00       159\n",
      "          81       0.00      0.00      0.00       138\n",
      "          82       0.00      0.00      0.00       116\n",
      "          83       0.00      0.00      0.00       107\n",
      "          84       0.00      0.00      0.00       113\n",
      "          85       0.00      0.00      0.00       117\n",
      "          86       0.00      0.00      0.00       110\n",
      "          87       0.00      0.00      0.00       110\n",
      "          88       0.00      0.00      0.00       102\n",
      "          89       0.00      0.00      0.00        94\n",
      "          90       0.00      0.00      0.00        87\n",
      "          91       0.00      0.00      0.00        85\n",
      "          92       0.00      0.00      0.00        89\n",
      "          93       0.00      0.00      0.00        82\n",
      "          94       0.08      0.03      0.05        92\n",
      "          95       0.00      0.00      0.00        75\n",
      "          96       0.00      0.00      0.00        73\n",
      "          97       0.09      0.01      0.02        81\n",
      "          98       0.00      0.00      0.00        79\n",
      "          99       0.00      0.00      0.00        82\n",
      "         100       0.00      0.00      0.00        75\n",
      "         101       0.00      0.00      0.00        78\n",
      "         102       0.00      0.00      0.00        79\n",
      "         103       0.00      0.00      0.00        78\n",
      "         104       0.00      0.00      0.00        80\n",
      "         105       0.00      0.00      0.00        83\n",
      "         106       0.00      0.00      0.00        81\n",
      "         107       0.00      0.00      0.00        82\n",
      "         108       0.00      0.00      0.00       106\n",
      "         109       0.00      0.00      0.00       111\n",
      "         110       0.00      0.00      0.00       106\n",
      "         111       0.00      0.00      0.00        95\n",
      "         112       0.00      0.00      0.00        73\n",
      "         113       0.00      0.00      0.00        65\n",
      "         114       0.00      0.00      0.00        62\n",
      "         115       0.00      0.00      0.00        68\n",
      "         116       0.00      0.00      0.00        57\n",
      "         117       0.00      0.00      0.00        59\n",
      "         118       0.00      0.00      0.00        72\n",
      "         119       0.00      0.00      0.00        87\n",
      "         120       0.00      0.00      0.00       114\n",
      "         121       0.00      0.00      0.00       130\n",
      "         122       0.00      0.00      0.00       125\n",
      "         123       0.00      0.00      0.00       128\n",
      "         124       0.05      0.01      0.01       115\n",
      "         125       0.00      0.00      0.00        96\n",
      "         126       0.00      0.00      0.00        91\n",
      "         127       0.25      0.01      0.02        80\n",
      "         128       0.00      0.00      0.00        72\n",
      "         129       0.00      0.00      0.00        75\n",
      "         130       0.00      0.00      0.00        74\n",
      "         131       0.00      0.00      0.00        64\n",
      "         132       0.11      0.02      0.03        65\n",
      "         133       0.00      0.00      0.00        78\n",
      "         134       0.00      0.00      0.00        68\n",
      "         135       0.00      0.00      0.00        72\n",
      "         136       0.00      0.00      0.00        73\n",
      "         137       0.10      0.01      0.02        75\n",
      "         138       0.00      0.00      0.00        82\n",
      "         139       0.00      0.00      0.00        76\n",
      "         140       0.00      0.00      0.00        82\n",
      "         141       0.00      0.00      0.00        89\n",
      "         142       0.04      0.01      0.02        80\n",
      "         143       0.00      0.00      0.00        75\n",
      "         144       0.00      0.00      0.00        76\n",
      "         145       0.00      0.00      0.00        68\n",
      "         146       0.00      0.00      0.00        60\n",
      "         147       0.00      0.00      0.00        56\n",
      "         148       0.00      0.00      0.00        57\n",
      "         149       0.00      0.00      0.00        59\n",
      "         150       0.08      0.02      0.03        60\n",
      "         151       0.00      0.00      0.00        66\n",
      "         152       0.00      0.00      0.00        66\n",
      "         153       0.00      0.00      0.00        64\n",
      "         154       0.00      0.00      0.00        65\n",
      "         155       0.00      0.00      0.00        58\n",
      "         156       0.08      0.02      0.03        63\n",
      "         157       0.00      0.00      0.00        66\n",
      "         158       0.00      0.00      0.00        56\n",
      "         159       0.00      0.00      0.00        62\n",
      "         160       0.00      0.00      0.00        63\n",
      "         161       0.09      0.02      0.03        59\n",
      "         162       0.00      0.00      0.00        59\n",
      "         163       0.00      0.00      0.00        58\n",
      "         164       0.00      0.00      0.00        54\n",
      "         165       0.00      0.00      0.00        65\n",
      "         166       0.00      0.00      0.00        58\n",
      "         167       0.00      0.00      0.00        66\n",
      "         168       0.00      0.00      0.00        68\n",
      "         169       0.00      0.00      0.00        68\n",
      "         170       0.00      0.00      0.00        63\n",
      "         171       0.08      0.02      0.03        65\n",
      "         172       0.00      0.00      0.00        53\n",
      "         173       0.00      0.00      0.00        54\n",
      "         174       0.00      0.00      0.00        55\n",
      "         175       0.10      0.02      0.03        49\n",
      "         176       0.00      0.00      0.00        40\n",
      "         177       0.00      0.00      0.00        38\n",
      "         178       0.38      0.07      0.12        42\n",
      "         179       0.00      0.00      0.00        34\n",
      "         180       0.00      0.00      0.00        31\n",
      "         181       0.00      0.00      0.00        33\n",
      "         182       0.00      0.00      0.00        39\n",
      "         183       0.20      0.10      0.14        39\n",
      "         184       0.00      0.00      0.00        36\n",
      "         185       0.25      0.03      0.05        36\n",
      "         186       0.00      0.00      0.00        33\n",
      "         187       0.00      0.00      0.00        35\n",
      "         188       0.00      0.00      0.00        39\n",
      "         189       0.11      0.12      0.11        43\n",
      "         190       0.07      0.26      0.11        58\n",
      "         191       0.00      0.00      0.00        26\n",
      "         192       0.00      0.00      0.00        30\n",
      "         193       0.10      0.37      0.16       118\n",
      "         194       0.03      0.03      0.03        37\n",
      "         195       0.00      0.00      0.00        28\n",
      "         196       0.00      0.00      0.00        29\n",
      "         197       0.06      0.13      0.08        61\n",
      "         198       0.00      0.00      0.00        26\n",
      "         199       0.00      0.00      0.00        31\n",
      "         200       0.00      0.00      0.00        22\n",
      "         201       0.00      0.00      0.00        25\n",
      "         202       0.00      0.00      0.00        25\n",
      "         203       0.00      0.00      0.00        20\n",
      "         204       0.00      0.00      0.00        20\n",
      "         205       0.00      0.00      0.00        21\n",
      "         206       0.00      0.00      0.00        30\n",
      "         207       0.00      0.00      0.00        22\n",
      "         208       0.00      0.00      0.00        55\n",
      "         209       0.07      0.19      0.11       253\n",
      "         210       0.12      0.52      0.20       723\n",
      "         211       0.09      0.40      0.15       539\n",
      "         212       0.11      0.35      0.16       261\n",
      "\n",
      "    accuracy                           0.05     58291\n",
      "   macro avg       0.03      0.02      0.02     58291\n",
      "weighted avg       0.04      0.05      0.03     58291\n",
      "\n",
      "AUC ROC Score for Test Set: 0.7691\n"
     ]
    }
   ],
   "source": [
    "# Define the Feed Forward Neural Network model\n",
    "best_model = MLPClassifier(random_state=42)\n",
    "\n",
    "# Fit the model on the training set\n",
    "best_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_test_pred = best_model.predict(X_test_scaled)\n",
    "\n",
    "# Predict probabilities for ROC AUC curve\n",
    "y_test_proba = best_model.predict_proba(X_test_scaled)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_report = classification_report(y_test, y_test_pred)\n",
    "print(\"Classification Report for Test Set:\\n\")\n",
    "print(test_report)\n",
    "\n",
    "# Calculate AUC ROC for the test set\n",
    "try:\n",
    "    auc_roc_test = roc_auc_score(y_test, y_test_proba, multi_class='ovr')\n",
    "    print(f\"AUC ROC Score for Test Set: {auc_roc_test:.4f}\")\n",
    "except ValueError:\n",
    "    auc_roc_test = None  # Handle models that don't support probability prediction\n",
    "    print(\"AUC ROC could not be calculated for the test set.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix for Test Set:\n",
      " [[  7   8   7 ...   1   1   0]\n",
      " [  6  10  10 ...   4   4   0]\n",
      " [  5   4  10 ...   4   3   4]\n",
      " ...\n",
      " [  0   1   1 ... 377  65   8]\n",
      " [  0   0   0 ... 116 216  39]\n",
      " [  0   0   1 ...   6 106  92]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "conf_matrix_test = confusion_matrix(y_test, y_test_pred)\n",
    "print(\"\\nConfusion Matrix for Test Set:\\n\", conf_matrix_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
